{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with parquet files\n",
    "\n",
    "## Objective\n",
    "\n",
    "+ In this assignment, we will use the data downloaded with the module `data_manager` to create features.\n",
    "\n",
    "(11 pts total)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "+ This notebook assumes that price data is available to you in the environment variable `PRICE_DATA`. If you have not done so, then execute the notebook `01_materials/labs/2_data_engineering.ipynb` to create this data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Load the environment variables using dotenv. (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below.\n",
    "%load_ext dotenv \n",
    "%dotenv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Load the environment variable `PRICE_DATA`.\n",
    "+ Use [glob](https://docs.python.org/3/library/glob.html) to find the path of all parquet files in the directory `PRICE_DATA`.\n",
    "\n",
    "(1pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date       Open       High        Low      Close  Adj Close  \\\n",
      "ticker                                                                     \n",
      "BBUS   2019-03-13  50.630001  50.669998  50.513000  50.513000  49.567730   \n",
      "BBUS   2019-03-14  50.500000  50.542000  50.439999  50.500000  49.554974   \n",
      "BBUS   2019-03-15  50.599998  50.698002  50.599998  50.698002  49.749268   \n",
      "BBUS   2019-03-18  50.860001  50.946999  50.750000  50.910999  49.958282   \n",
      "BBUS   2019-03-19  51.150002  51.169998  50.855999  50.863998  49.912159   \n",
      "\n",
      "         Volume    source  Year  \n",
      "ticker                           \n",
      "BBUS    27300.0  BBUS.csv  2019  \n",
      "BBUS     4000.0  BBUS.csv  2019  \n",
      "BBUS      900.0  BBUS.csv  2019  \n",
      "BBUS    16900.0  BBUS.csv  2019  \n",
      "BBUS    14800.0  BBUS.csv  2019  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Write your code below.\n",
    "# Load all parquet files from PRICE_DATA environment variable path\n",
    "PRICE_DATA = os.getenv(\"PRICE_DATA\")\n",
    "parquet_files = glob(os.path.join(PRICE_DATA, \"**/*.parquet\"), recursive = True)\n",
    "\n",
    "#print(parquet_files)\n",
    "dd_px = dd.read_parquet(parquet_files).set_index(\"ticker\")\n",
    "print(dd_px.compute().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each ticker and using Dask, do the following:\n",
    "\n",
    "+ Add lags for variables Close and Adj_Close.\n",
    "+ Add returns based on Close:\n",
    "    \n",
    "    - `returns`: (Close / Close_lag_1) - 1\n",
    "\n",
    "+ Add the following range: \n",
    "\n",
    "    - `hi_lo_range`: this is the day's High minus Low.\n",
    "\n",
    "+ Assign the result to `dd_feat`.\n",
    "\n",
    "(4 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunib\\AppData\\Local\\Temp\\ipykernel_25908\\148348221.py:4: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  dd_cls = dd_px.groupby('ticker', group_keys=False).apply(\n",
      "C:\\Users\\sunib\\AppData\\Local\\Temp\\ipykernel_25908\\148348221.py:8: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  dd_adj= dd_cls.groupby('ticker', group_keys=False).apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>source</th>\n",
       "      <th>Year</th>\n",
       "      <th>Close_lag_1</th>\n",
       "      <th>Adj_Close_lag_1</th>\n",
       "      <th>returns</th>\n",
       "      <th>hi_lo_range</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BBUS</th>\n",
       "      <td>2019-03-13</td>\n",
       "      <td>50.630001</td>\n",
       "      <td>50.669998</td>\n",
       "      <td>50.513000</td>\n",
       "      <td>50.513000</td>\n",
       "      <td>49.567730</td>\n",
       "      <td>27300.0</td>\n",
       "      <td>BBUS.csv</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBUS</th>\n",
       "      <td>2019-03-14</td>\n",
       "      <td>50.500000</td>\n",
       "      <td>50.542000</td>\n",
       "      <td>50.439999</td>\n",
       "      <td>50.500000</td>\n",
       "      <td>49.554974</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>BBUS.csv</td>\n",
       "      <td>2019</td>\n",
       "      <td>50.513000</td>\n",
       "      <td>49.567730</td>\n",
       "      <td>-0.000257</td>\n",
       "      <td>0.102001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBUS</th>\n",
       "      <td>2019-03-15</td>\n",
       "      <td>50.599998</td>\n",
       "      <td>50.698002</td>\n",
       "      <td>50.599998</td>\n",
       "      <td>50.698002</td>\n",
       "      <td>49.749268</td>\n",
       "      <td>900.0</td>\n",
       "      <td>BBUS.csv</td>\n",
       "      <td>2019</td>\n",
       "      <td>50.500000</td>\n",
       "      <td>49.554974</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.098003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBUS</th>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>50.860001</td>\n",
       "      <td>50.946999</td>\n",
       "      <td>50.750000</td>\n",
       "      <td>50.910999</td>\n",
       "      <td>49.958282</td>\n",
       "      <td>16900.0</td>\n",
       "      <td>BBUS.csv</td>\n",
       "      <td>2019</td>\n",
       "      <td>50.698002</td>\n",
       "      <td>49.749268</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.196999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBUS</th>\n",
       "      <td>2019-03-19</td>\n",
       "      <td>51.150002</td>\n",
       "      <td>51.169998</td>\n",
       "      <td>50.855999</td>\n",
       "      <td>50.863998</td>\n",
       "      <td>49.912159</td>\n",
       "      <td>14800.0</td>\n",
       "      <td>BBUS.csv</td>\n",
       "      <td>2019</td>\n",
       "      <td>50.910999</td>\n",
       "      <td>49.958282</td>\n",
       "      <td>-0.000923</td>\n",
       "      <td>0.313999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XMHQ</th>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>41.830002</td>\n",
       "      <td>41.830002</td>\n",
       "      <td>41.830002</td>\n",
       "      <td>41.830002</td>\n",
       "      <td>41.830002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>XMHQ.csv</td>\n",
       "      <td>2020</td>\n",
       "      <td>39.830002</td>\n",
       "      <td>39.830002</td>\n",
       "      <td>0.050213</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XMHQ</th>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>40.299999</td>\n",
       "      <td>40.549999</td>\n",
       "      <td>40.110001</td>\n",
       "      <td>40.480000</td>\n",
       "      <td>40.480000</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>XMHQ.csv</td>\n",
       "      <td>2020</td>\n",
       "      <td>41.830002</td>\n",
       "      <td>41.830002</td>\n",
       "      <td>-0.032274</td>\n",
       "      <td>0.439999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XMHQ</th>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>40.810001</td>\n",
       "      <td>41.970001</td>\n",
       "      <td>40.810001</td>\n",
       "      <td>41.970001</td>\n",
       "      <td>41.970001</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>XMHQ.csv</td>\n",
       "      <td>2020</td>\n",
       "      <td>40.480000</td>\n",
       "      <td>40.480000</td>\n",
       "      <td>0.036808</td>\n",
       "      <td>1.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XMHQ</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>42.110001</td>\n",
       "      <td>42.110001</td>\n",
       "      <td>41.049999</td>\n",
       "      <td>41.259998</td>\n",
       "      <td>41.259998</td>\n",
       "      <td>600.0</td>\n",
       "      <td>XMHQ.csv</td>\n",
       "      <td>2020</td>\n",
       "      <td>41.970001</td>\n",
       "      <td>41.970001</td>\n",
       "      <td>-0.016917</td>\n",
       "      <td>1.060001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XMHQ</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>39.480000</td>\n",
       "      <td>39.480000</td>\n",
       "      <td>39.349998</td>\n",
       "      <td>39.349998</td>\n",
       "      <td>39.349998</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>XMHQ.csv</td>\n",
       "      <td>2020</td>\n",
       "      <td>41.259998</td>\n",
       "      <td>41.259998</td>\n",
       "      <td>-0.046292</td>\n",
       "      <td>0.130001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102693 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date       Open       High        Low      Close  Adj Close  \\\n",
       "ticker                                                                     \n",
       "BBUS   2019-03-13  50.630001  50.669998  50.513000  50.513000  49.567730   \n",
       "BBUS   2019-03-14  50.500000  50.542000  50.439999  50.500000  49.554974   \n",
       "BBUS   2019-03-15  50.599998  50.698002  50.599998  50.698002  49.749268   \n",
       "BBUS   2019-03-18  50.860001  50.946999  50.750000  50.910999  49.958282   \n",
       "BBUS   2019-03-19  51.150002  51.169998  50.855999  50.863998  49.912159   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "XMHQ   2020-03-26  41.830002  41.830002  41.830002  41.830002  41.830002   \n",
       "XMHQ   2020-03-27  40.299999  40.549999  40.110001  40.480000  40.480000   \n",
       "XMHQ   2020-03-30  40.810001  41.970001  40.810001  41.970001  41.970001   \n",
       "XMHQ   2020-03-31  42.110001  42.110001  41.049999  41.259998  41.259998   \n",
       "XMHQ   2020-04-01  39.480000  39.480000  39.349998  39.349998  39.349998   \n",
       "\n",
       "         Volume    source  Year  Close_lag_1  Adj_Close_lag_1   returns  \\\n",
       "ticker                                                                    \n",
       "BBUS    27300.0  BBUS.csv  2019          NaN              NaN       NaN   \n",
       "BBUS     4000.0  BBUS.csv  2019    50.513000        49.567730 -0.000257   \n",
       "BBUS      900.0  BBUS.csv  2019    50.500000        49.554974  0.003921   \n",
       "BBUS    16900.0  BBUS.csv  2019    50.698002        49.749268  0.004201   \n",
       "BBUS    14800.0  BBUS.csv  2019    50.910999        49.958282 -0.000923   \n",
       "...         ...       ...   ...          ...              ...       ...   \n",
       "XMHQ      100.0  XMHQ.csv  2020    39.830002        39.830002  0.050213   \n",
       "XMHQ     1900.0  XMHQ.csv  2020    41.830002        41.830002 -0.032274   \n",
       "XMHQ     2000.0  XMHQ.csv  2020    40.480000        40.480000  0.036808   \n",
       "XMHQ      600.0  XMHQ.csv  2020    41.970001        41.970001 -0.016917   \n",
       "XMHQ     3100.0  XMHQ.csv  2020    41.259998        41.259998 -0.046292   \n",
       "\n",
       "        hi_lo_range  \n",
       "ticker               \n",
       "BBUS       0.156998  \n",
       "BBUS       0.102001  \n",
       "BBUS       0.098003  \n",
       "BBUS       0.196999  \n",
       "BBUS       0.313999  \n",
       "...             ...  \n",
       "XMHQ       0.000000  \n",
       "XMHQ       0.439999  \n",
       "XMHQ       1.160000  \n",
       "XMHQ       1.060001  \n",
       "XMHQ       0.130001  \n",
       "\n",
       "[102693 rows x 13 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code below.\n",
    "\n",
    "#Add lagged features and calculate returns and hi_lo_range\n",
    "dd_cls = dd_px.groupby('ticker', group_keys=False).apply(\n",
    "    lambda x: x.assign(Close_lag_1 = x['Close'].shift(1))\n",
    ")\n",
    "\n",
    "dd_adj= dd_cls.groupby('ticker', group_keys=False).apply(\n",
    "lambda x: x.assign(Adj_Close_lag_1 = x['Adj Close'].shift(1))\n",
    ")\n",
    "\n",
    "dd_rets = dd_adj.assign(\n",
    "    returns = lambda x: x['Close']/x['Close_lag_1'] - 1,\n",
    "    hi_lo_range = lambda x: x['High'] - x['Low']\n",
    ")\n",
    "\n",
    "df_feat = dd_rets.compute()\n",
    "df_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Convert the Dask data frame to a pandas data frame. \n",
    "+ Add a new feature containing the moving average of `returns` using a window of 10 days. There are several ways to solve this task, a simple one uses `.rolling(10).mean()`.\n",
    "\n",
    "(3 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Verify the type of df_feat - Pandas DataFrame\n",
    "print(type(df_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date       Open       High        Low      Close  Adj Close  \\\n",
      "ticker                                                                     \n",
      "BBUS   2019-03-13  50.630001  50.669998  50.513000  50.513000  49.567730   \n",
      "BBUS   2019-03-14  50.500000  50.542000  50.439999  50.500000  49.554974   \n",
      "BBUS   2019-03-15  50.599998  50.698002  50.599998  50.698002  49.749268   \n",
      "BBUS   2019-03-18  50.860001  50.946999  50.750000  50.910999  49.958282   \n",
      "BBUS   2019-03-19  51.150002  51.169998  50.855999  50.863998  49.912159   \n",
      "BBUS   2019-03-20  50.900002  50.950001  50.590000  50.779999  49.829735   \n",
      "BBUS   2019-03-21  50.599998  51.400002  50.599998  51.334000  50.373367   \n",
      "BBUS   2019-03-22  51.169998  51.180000  50.330002  50.360001  49.417591   \n",
      "BBUS   2019-03-25  50.200001  50.400002  50.070000  50.307999  49.366562   \n",
      "BBUS   2019-03-26  50.660000  50.779999  50.436001  50.632000  49.684502   \n",
      "\n",
      "         Volume    source  Year  Close_lag_1  Adj_Close_lag_1   returns  \\\n",
      "ticker                                                                    \n",
      "BBUS    27300.0  BBUS.csv  2019          NaN              NaN       NaN   \n",
      "BBUS     4000.0  BBUS.csv  2019    50.513000        49.567730 -0.000257   \n",
      "BBUS      900.0  BBUS.csv  2019    50.500000        49.554974  0.003921   \n",
      "BBUS    16900.0  BBUS.csv  2019    50.698002        49.749268  0.004201   \n",
      "BBUS    14800.0  BBUS.csv  2019    50.910999        49.958282 -0.000923   \n",
      "BBUS    12900.0  BBUS.csv  2019    50.863998        49.912159 -0.001651   \n",
      "BBUS     3100.0  BBUS.csv  2019    50.779999        49.829735  0.010910   \n",
      "BBUS    24700.0  BBUS.csv  2019    51.334000        50.373367 -0.018974   \n",
      "BBUS     4800.0  BBUS.csv  2019    50.360001        49.417591 -0.001033   \n",
      "BBUS     4200.0  BBUS.csv  2019    50.307999        49.366562  0.006440   \n",
      "\n",
      "        hi_lo_range  returns_ma10  \n",
      "ticker                             \n",
      "BBUS       0.156998           NaN  \n",
      "BBUS       0.102001           NaN  \n",
      "BBUS       0.098003           NaN  \n",
      "BBUS       0.196999           NaN  \n",
      "BBUS       0.313999           NaN  \n",
      "BBUS       0.360001           NaN  \n",
      "BBUS       0.800003           NaN  \n",
      "BBUS       0.849998           NaN  \n",
      "BBUS       0.330002           NaN  \n",
      "BBUS       0.343998           NaN  \n"
     ]
    }
   ],
   "source": [
    "# Write your code below.\n",
    "\n",
    "# Convert the \"Date\" column to datetime format\n",
    "df_feat[\"Date\"] = pd.to_datetime(df_feat[\"Date\"])\n",
    "\n",
    "#Sort the DataFrame by ticker and Date\n",
    "df_feat = df_feat.sort_values([\"ticker\", \"Date\"])\n",
    " \n",
    "# Calculate the 10 day moving average of the \"returns\" column for each ticker\n",
    "df_feat['returns_ma10'] = df_feat.groupby('ticker')['returns'].transform(lambda x: x.rolling(10).mean())\n",
    "\n",
    "print(df_feat.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please comment:\n",
    "\n",
    "+ Was it necessary to convert to pandas to calculate the moving average return?\n",
    "+ Would it have been better to do it in Dask? Why?\n",
    "\n",
    "(1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It wasnâ€™t strictly necessary to convert the Dask DataFrame to pandas to calculate the moving average, because Dask can do rolling calculations too. However, using Pandas is much easier and more reliable, especially when working with groups like different tickers. Dask is better for very large datasets, but its rolling functions are more limited and harder to use. If data is small enough to fit in memory, pandas is simpler and easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criteria\n",
    "\n",
    "The [rubric](./assignment_1_rubric_clean.xlsx) contains the criteria for grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Information\n",
    "\n",
    "ðŸš¨ **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** ðŸš¨ for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "### Submission Parameters:\n",
    "* Submission Due Date: `HH:MM AM/PM - DD/MM/YYYY`\n",
    "* The branch name for your repo should be: `assignment-1`\n",
    "* What to submit for this assignment:\n",
    "    * This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "* What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    * Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "Checklist:\n",
    "- [ ] Created a branch with the correct naming convention.\n",
    "- [ ] Ensured that the repository is public.\n",
    "- [ ] Reviewed the PR description guidelines and adhered to them.\n",
    "- [ ] Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack at `#cohort-3-help`. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
